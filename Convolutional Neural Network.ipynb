{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load necessary libraries ###\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define helper functions ###\n",
    "def extract_features(parent_dir,sub_dirs,file_ext=\"*.wav\",\n",
    "                     bands=60,frames=41):\n",
    "    def _windows(data, window_size):\n",
    "        start = 0\n",
    "        while start < len(data):\n",
    "            yield int(start), int(start + window_size)\n",
    "            start += (window_size // 2)\n",
    "            \n",
    "    window_size = 512 * (frames - 1)\n",
    "    features, labels = [], []\n",
    "    for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "        segment_log_specgrams, segment_labels = [], []\n",
    "        sound_clip,sr = librosa.load(fn)\n",
    "        label = int(fn.split('/')[2].split('-')[1])\n",
    "        for (start,end) in _windows(sound_clip,window_size):\n",
    "            if(len(sound_clip[start:end]) == window_size):\n",
    "                signal = sound_clip[start:end]\n",
    "                melspec = librosa.feature.melspectrogram(signal,n_mels=bands)\n",
    "                logspec = librosa.amplitude_to_db(melspec)\n",
    "                logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                segment_log_specgrams.append(logspec)\n",
    "                segment_labels.append(label)\n",
    "            \n",
    "        segment_log_specgrams = np.asarray(segment_log_specgrams).reshape(\n",
    "            len(segment_log_specgrams),bands,frames,1)\n",
    "        segment_features = np.concatenate((segment_log_specgrams, np.zeros(\n",
    "            np.shape(segment_log_specgrams))), axis=3)\n",
    "        for i in range(len(segment_features)): \n",
    "            segment_features[i, :, :, 1] = librosa.feature.delta(\n",
    "                segment_features[i, :, :, 0])\n",
    "        \n",
    "        if len(segment_features) > 0: # check for empty segments \n",
    "            features.append(segment_features)\n",
    "            labels.append(segment_labels)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process and extract feature from the data\n",
    "parent_dir = 'UrbanSounds8K/audio/'\n",
    "save_dir = \"UrbanSounds8K/processed/\"\n",
    "folds = sub_dirs = np.array(['fold1','fold2','fold3','fold4',\n",
    "                  'fold5','fold6','fold7','fold8',\n",
    "                  'fold9','fold10'])\n",
    "for sub_dir in sub_dirs:\n",
    "    features, labels = extract_features(parent_dir,sub_dir)\n",
    "    np.savez(\"{0}{1}\".format(save_dir, sub_dir), \n",
    "             features=features, \n",
    "             labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define convolutional network architecture ###\n",
    "def get_network():\n",
    "    num_filters = [24,32,64,128] \n",
    "    pool_size = (2, 2) \n",
    "    kernel_size = (3, 3)  \n",
    "    input_shape = (60, 41, 2)\n",
    "    num_classes = 10\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(24, kernel_size,\n",
    "                padding=\"same\", input_shape=input_shape))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size,\n",
    "                                  padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))  \n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(64, kernel_size,\n",
    "                                  padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))  \n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, kernel_size,\n",
    "                                  padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))  \n",
    "\n",
    "    model.add(keras.layers.GlobalMaxPooling2D())\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-4), \n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "        metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and evaluate via 10-Folds cross-validation ###\n",
    "accuracies = []\n",
    "folds = np.array(['fold1','fold2','fold3','fold4',\n",
    "                  'fold5','fold6','fold7','fold8',\n",
    "                  'fold9','fold10'])\n",
    "load_dir = \"UrbanSounds8K/processed/\"\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(folds):\n",
    "    x_train, y_train = [], []\n",
    "    for ind in train_index:\n",
    "        # read features or segments of an audio file\n",
    "        train_data = np.load(\"{0}/{1}.npz\".format(load_dir,folds[ind]), \n",
    "                       allow_pickle=True)\n",
    "        # for training stack all the segments so that they are treated as an example/instance\n",
    "        features = np.concatenate(train_data[\"features\"], axis=0) \n",
    "        labels = np.concatenate(train_data[\"labels\"], axis=0)\n",
    "        x_train.append(features)\n",
    "        y_train.append(labels)\n",
    "    # stack x,y pairs of all training folds \n",
    "    x_train = np.concatenate(x_train, axis = 0).astype(np.float32)\n",
    "    y_train = np.concatenate(y_train, axis = 0).astype(np.float32)\n",
    "    \n",
    "    # for testing we will make predictions on each segment and average them to \n",
    "    # produce signle label for an entire sound clip.\n",
    "    test_data = np.load(\"{0}/{1}.npz\".format(load_dir,\n",
    "                   folds[test_index][0]), allow_pickle=True)\n",
    "    x_test = test_data[\"features\"]\n",
    "    y_test = test_data[\"labels\"]\n",
    "\n",
    "    model = get_network()\n",
    "    model.fit(x_train, y_train, epochs = 50, batch_size = 24, verbose = 0)\n",
    "    \n",
    "    # evaluate on test set/fold\n",
    "    y_true, y_pred = [], []\n",
    "    for x, y in zip(x_test, y_test):\n",
    "        # average predictions over segments of a sound clip\n",
    "        avg_p = np.argmax(np.mean(model.predict(x), axis = 0))\n",
    "        y_pred.append(avg_p) \n",
    "        # pick single label via np.unique for a sound clip\n",
    "        y_true.append(np.unique(y)[0]) \n",
    "    accuracies.append(accuracy_score(y_true, y_pred))    \n",
    "print(\"Average 10 Folds Accuracy: {0}\".format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
