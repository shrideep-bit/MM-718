{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load necessary libraries ###\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define helper functions ###\n",
    "def load_sound_files(file_paths):\n",
    "    raw_sounds = []\n",
    "    for fp in file_paths:\n",
    "        X,sr = librosa.load(fp)\n",
    "        raw_sounds.append(X)\n",
    "    return raw_sounds\n",
    "\n",
    "def plot_waves(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi=900)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        librosa.display.waveplot(np.array(f),sr=22050)\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 1: Waveplot',x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_specgram(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi = 900)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        specgram(np.array(f), Fs=22050)\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 2: Spectrogram',x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "def plot_log_power_specgram(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi = 900)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        D = librosa.logamplitude(np.abs(librosa.stft(f))**2, ref_power=np.max)\n",
    "        librosa.display.specshow(D,x_axis='time' ,y_axis='log')\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 3: Log power spectrogram',x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz\n",
    "\n",
    "def parse_audio_files(parent_dir,sub_dir,file_ext='*.wav'):\n",
    "    features, labels = np.empty((0,193)), np.empty(0) # 193 => total features \n",
    "    for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "        mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
    "        ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "        features = np.vstack([features,ext_features])\n",
    "        labels = np.append(labels, int(fn.split('/')[2].split('-')[1]))\n",
    "    return np.array(features, dtype=np.float32), np.array(labels, dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot few sound clips along with their spectrograms ###\n",
    "sound_file_paths = [\"57320-0-0-7.wav\",\"24074-1-0-3.wav\",\n",
    "                    \"15564-2-0-1.wav\",\"31323-3-0-1.wav\",\n",
    "                    \"46669-4-0-35.wav\",\"89948-5-0-0.wav\",\n",
    "                    \"46656-6-0-0.wav\",\"103074-7-3-2.wav\",\n",
    "                    \"106905-8-0-0.wav\",\"108041-9-0-4.wav\"]\n",
    "sound_names = [\"air conditioner\",\"car horn\",\"children playing\",\n",
    "               \"dog bark\",\"drilling\",\"engine idling\",\n",
    "               \"gun shot\",\"jackhammer\",\"siren\",\"street music\"]\n",
    "\n",
    "raw_sounds = load_sound_files(sound_file_paths)\n",
    "plot_waves(sound_names,raw_sounds)\n",
    "plot_specgram(sound_names,raw_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process and extract feature from the data\n",
    "parent_dir = 'UrbanSounds8K/audio/'\n",
    "save_dir = \"UrbanSounds8K/processed/\"\n",
    "sub_dirs = np.array(['fold1','fold2','fold3','fold4',\n",
    "                  'fold5','fold6','fold7','fold8',\n",
    "                  'fold9','fold10'])\n",
    "for sub_dir in sub_dirs:\n",
    "    features, labels = parse_audio_files(parent_dir,sub_dir)\n",
    "    np.savez(\"{0}{1}\".format(save_dir, sub_dir), features=features, \n",
    "             labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define feedforward network architecture ###\n",
    "def get_network():\n",
    "    input_shape = (193,)\n",
    "    num_classes = 10\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(256, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(keras.layers.Dense(num_classes, activation = \"softmax\"))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-4), \n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "        metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and evaluate via 10-Folds cross-validation ###\n",
    "accuracies = []\n",
    "folds = np.array(['fold1','fold2','fold3','fold4',\n",
    "                  'fold5','fold6','fold7','fold8',\n",
    "                  'fold9','fold10'])\n",
    "load_dir = \"UrbanSounds8K/processed/\"\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(folds):\n",
    "    x_train, y_train = [], []\n",
    "    for ind in train_index:\n",
    "        data = np.load(\"{0}/{1}.npz\".format(load_dir,folds[ind]))\n",
    "        x_train.append(data[\"features\"])\n",
    "        y_train.append(data[\"labels\"])\n",
    "    x_train = np.concatenate(x_train, axis = 0)\n",
    "    y_train = np.concatenate(y_train, axis = 0)\n",
    "    \n",
    "    data = np.load(\"{0}/{1}.npz\".format(load_dir,folds[test_index][0]))\n",
    "    x_test = data[\"features\"]\n",
    "    y_test = data[\"labels\"]\n",
    "    \n",
    "    # Possibly do mean normalization here on x_train and x_test but using only x_train's mean and std.\n",
    "    \n",
    "    model = get_network()\n",
    "    model.fit(x_train, y_train, epochs = 50, batch_size = 24, verbose = 0)\n",
    "    l, a = model.evaluate(x_test, y_test, verbose = 0)\n",
    "    accuracies.append(a)\n",
    "    print(\"Loss: {0} | Accuracy: {1}\".format(l, a))\n",
    "    \n",
    "print(\"Average 10 Folds Accuracy: {0}\".format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
